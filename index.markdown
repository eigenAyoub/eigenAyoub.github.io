---
layout: home
---


$$\rightarrow$$ **CUDA/C++ learning series:** 
* [GPU architecture and warp scheduling](/blogs/gpu-architecture)

$$\rightarrow$$ **LLMs** 
* [Some notes on perplexity and beyond!](/blogs/ppl)
* [Recent trends to speed up autoregressive inference of LLMs (unifinished).](/blogs/fastinference)

$$\rightarrow$$ **Technical** 
* [Handling checkpoints from terminal - some useful tricks.](/blogs/linux)
* [Quick reset of my compute pod.](/blogs/container)
* [Speed up your migration to VIM.](/blogs/vim)
<!-- [Investigating Kronecker Products as  xx](/blogs/distill/main.pdf) -->

$$\rightarrow$$ **Math:** 
* [Matrix Differential Calculus.](/blogs/enter_the_matrix)
* [Convergence Rates of SGD in convex and non-convex cases.](/blogs/SGD)

<ins>**Some GitHub repos:**</ins>

* GPT2 factorized with (multiple) Kronecker Factors: $$\rightarrow$$ [Github link](https://github.com/eigenAyoub/krony-PT).
* Backpropagation from scratch $$\rightarrow$$ [Github link](https://github.com/eigenAyoub/check-your-gradients).
* Randomized Algorithms $$\rightarrow$$ [Github link](https://github.com/eigenAyoub/randomised-algorithms). 
* Reinforcement Learning $$\rightarrow$$ [Github link](https://github.com/eigenAyoub/reinforcement-learning).

<ins>**Bio/Contact:**</ins>

 üìçPassau, Germany. 
* I'm a part-time ML research assistant [@CAROLL](https://ca-roll.github.io/), working on LLMs. 
* I'm also a computational math master's student at [@UniPassau](https://www.uni-passau.de/en/msc-compmaths). 
* **Gmail:** `ayoub.benayad.467` ;  [LinkedIn](https://www.linkedin.com/in/benayad/) ; [Instagram](https://www.instagram.com/curl.ayoub/).
