I"ë<hr />
<p><strong>Blog:</strong></p>

<ul>
  <li><a href="/blogs/fastinference">Recent trends to speed up autoregressive inference of LLMs (unifinished)</a></li>
  <li>Quick hacks that you might find useful:
    <ul>
      <li><a href="/blogs/vim">Speed up your migration to VIM.</a></li>
      <li><a href="/blogs/enter_the_matrix">Matrix Differential Calculus</a></li>
    </ul>
  </li>
  <li>Convex Optimization:
    <ul>
      <li><a href="/blogs/SGD">Convergence Rates of SGD in convex and non-convex cases</a></li>
    </ul>
  </li>
</ul>

<hr />
<p><strong>A few repos:</strong></p>

<ul>
  <li>Backpropagation from scratch \(\rightarrow\) <a href="https://github.com/eigenAyoub/check-your-gradients">Github link</a>.</li>
  <li>Randomized Algorithms \(\rightarrow\) <a href="https://github.com/eigenAyoub/randomised-algorithms">Github link</a>.</li>
  <li>Reinforcement Learning \(\rightarrow\) <a href="https://github.com/eigenAyoub/reinforcement-learning">Github link</a>.</li>
</ul>

<hr />

:ET